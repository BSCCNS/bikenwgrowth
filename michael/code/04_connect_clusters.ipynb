{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Connecting existing clusters of a bicycle network\n",
    "## Project: Algorithmic bicycle network design\n",
    "#### Michael Szell, Tyler Perlman, Sayat Mimar, Gourab Ghoshal, Roberta Sinatra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes a city's existing bicycle network, as prepared in 01_prepare_networks, then connects the biggest clusters following greedy triangulation.\n",
    "\n",
    "Contact: Michael Szell (michael.szell@gmail.com)  \n",
    "Created: 2020-06-29  \n",
    "Last modified: 2020-07-21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False # If True, will produce plots and/or verbose output to double-check\n",
    "%run -i \"../parameters/parameters.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i path.py\n",
    "%run -i setup.py\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for placeid, placeinfo in cities.items():\n",
    "    print(placeid + \": Generating cluster connections\")\n",
    "\n",
    "    # Load networks\n",
    "    G_biketrack = csv_to_ig(PATH[\"data\"] + placeid + \"/\", placeid, 'biketrack')\n",
    "    G_carall = csv_to_ig(PATH[\"data\"] + placeid + \"/\", placeid, 'carall')\n",
    "    G_biketrackcarall = csv_to_ig(PATH[\"data\"] + placeid + \"/\", placeid, 'biketrackcarall')\n",
    "    G = copy.deepcopy(G_biketrack) # G is the bike graph we are working with\n",
    "    \n",
    "    # Prepare clusterinfo\n",
    "    clusters = []\n",
    "    clusterinfo = {}\n",
    "    i = 0\n",
    "    total_length = sum(G.es[\"weight\"])\n",
    "    for j in range(len(list(G.components()))):\n",
    "        if len(list(G.components())[j]) > 1:\n",
    "            clusterinfo[i] = {\"size\": G.subgraph(list(G.components())[j]).vcount(), \n",
    "                              \"centroid_id\": highest_closeness_node(G.subgraph(list(G.components())[j]))[0],\n",
    "                              \"length\": sum(G.subgraph(list(G.components())[j]).es[\"weight\"])\n",
    "                              }\n",
    "            clusterinfo[i][\"centroid_index\"] = G.vs.find(id = clusterinfo[i]['centroid_id']).index\n",
    "            i += 1\n",
    "\n",
    "    cluster_indices = clusterindices_by_length(clusterinfo)\n",
    "\n",
    "    clusterinfo_temp = {}\n",
    "    length_covered = 0\n",
    "    \n",
    "    numclusters = 0\n",
    "    for c in cluster_indices:\n",
    "        if cutofftype == \"abs\" and clusterinfo[c][\"length\"] < cutoff/1000:\n",
    "            break\n",
    "        clusters.append(G.subgraph(list(G.components())[c]))\n",
    "        clusterinfo_temp[numclusters] = clusterinfo[c]\n",
    "        length_covered += clusterinfo[c][\"length\"]\n",
    "        numclusters += 1\n",
    "        if cutofftype == \"rel\" and length_covered >= cutoff*total_length:\n",
    "            break\n",
    "\n",
    "    print('{:d}'.format(numclusters) + \" largest clusters of \" + '{:d}'.format(len(list(G.components()))) + \" considered. Length covered: \" + '{:.2f}'.format(length_covered) + \" km (\" + '{:.0f}'.format(100*length_covered/total_length) + \"% of total length)\")\n",
    "\n",
    "    clusterinfo = copy.deepcopy(clusterinfo_temp)\n",
    "    cluster_indices = clusterindices_by_length(clusterinfo)\n",
    "\n",
    "    # Generation\n",
    "    GTs, GT_abstracts = greedy_triangulation_routing_clusters(G, G_biketrackcarall, clusters, clusterinfo, prune_quantiles, prune_measure)\n",
    "\n",
    "    for GT in GTs:\n",
    "        delete_overlaps(GT, G_biketrack)\n",
    "\n",
    "    # Write results\n",
    "    results = {\"placeid\": placeid, \"prune_measure\": prune_measure, \"prune_quantiles\": prune_quantiles, \"GTs\": GTs, \"GT_abstracts\": GT_abstracts, \"clusters\": clusters, \"clusterinfo\": clusterinfo, \"cutoff\": cutoff, \"cutofftype\": cutofftype}\n",
    "\n",
    "    filename = placeid + '_clusters_' + prune_measure + \"_cutoff\" + cutofftype + \"{:.2f}\".format(cutoff) + \".pickle\"\n",
    "    with open(PATH[\"results\"] + placeid + \"/\" + filename, 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sound_file, autoplay=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OSMNX",
   "language": "python",
   "name": "osmnx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
