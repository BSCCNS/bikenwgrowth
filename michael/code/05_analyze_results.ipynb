{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze bicycle network results\n",
    "## Project: Bicycle network analysis with Gourab, Sayat, Tyler, Michael, Roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the results from 03_poi_based_generation and 04_connect_clusters and calculates/analyzes a number of measures.\n",
    "\n",
    "Contact: Michael Szell (michael.szell@gmail.com)  \n",
    "Created: 2020-07-08  \n",
    "Last modified: 2020-07-08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import copy\n",
    "import math\n",
    "from haversine import haversine, haversine_vector\n",
    "import pprint\n",
    "import sys\n",
    "import random\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "from functools import partial\n",
    "import pyproj\n",
    "from shapely.geometry import Point, Polygon\n",
    "import shapely\n",
    "import shapely.ops as ops\n",
    "from itertools import combinations\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "\n",
    "import watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeid = \"paris\"\n",
    "prune_measure = \"betweenness\"\n",
    "poi_source = \"railwaystation\" # popdensity, grid\n",
    "\n",
    "PATH = {}\n",
    "PATH[\"data\"] = \"../data/\"\n",
    "PATH[\"plots\"] = \"../plots/\"\n",
    "PATH[\"results\"] = \"../results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph plotting preparation functions\n",
    "def my_plot_reset(G, nids = False):\n",
    "    reset_plot_attributes(G)\n",
    "    color_nodes(G, \"red\", nids)\n",
    "    size_nodes(G, 8, nids)\n",
    "\n",
    "def reset_plot_attributes(G):\n",
    "    \"\"\"Resets node attributes for plotting.\n",
    "    All black and size 0.\n",
    "    \"\"\"\n",
    "    G.vs[\"color\"] = \"black\"\n",
    "    G.vs[\"size\"] = 0\n",
    "        \n",
    "def color_nodes(G, color = \"blue\", nids = False, use_id = True):\n",
    "    \"\"\"Sets the color attribute of a set of nodes nids.\n",
    "    \"\"\"\n",
    "    if nids is False:\n",
    "        nids = [v.index for v in G.vs]\n",
    "        use_id = False\n",
    "    if use_id:\n",
    "        for nid in set(nids):\n",
    "            G.vs.find(id = nid)[\"color\"] = color\n",
    "    else:\n",
    "        G.vs[nids][\"color\"] = color\n",
    "\n",
    "def size_nodes(G, size = 5, nids = False, use_id = True):\n",
    "    \"\"\"Sets the size attribute of a set of nodes nids.\n",
    "    \"\"\"\n",
    "    if nids is False:\n",
    "        nids = [v.index for v in G.vs]\n",
    "        use_id = False\n",
    "    if use_id:\n",
    "        for nid in set(nids):\n",
    "            G.vs.find(id = nid)[\"size\"] = size\n",
    "    else:\n",
    "        G.vs[nids][\"size\"] = size\n",
    "\n",
    "def color_edges(G, color = \"blue\", eids = False):\n",
    "    \"\"\"Sets the color attribute of a set of edge nids.\n",
    "    \"\"\"\n",
    "    if eids is False:\n",
    "        G.es[\"color\"] = color\n",
    "    else:\n",
    "        G.es[eids][\"color\"] = color\n",
    "        \n",
    "def width_edges(G, width = 1, eids = False):\n",
    "    \"\"\"Sets the width attribute of a set of edge nids.\n",
    "    \"\"\"\n",
    "    if eids is False:\n",
    "        G.es[\"width\"] = width\n",
    "    else:\n",
    "        G.es[eids][\"width\"] = width\n",
    "        \n",
    "# Other functions\n",
    "def round_coordinates(G, r = 7):\n",
    "    for v in G.vs:\n",
    "        G.vs[v.index][\"x\"] = round(G.vs[v.index][\"x\"], r)\n",
    "        G.vs[v.index][\"y\"] = round(G.vs[v.index][\"y\"], r)\n",
    "\n",
    "def mirror_y(G):\n",
    "    for v in G.vs:\n",
    "        y = G.vs[v.index][\"y\"]\n",
    "        G.vs[v.index][\"y\"] = -y\n",
    "\n",
    "def dist(v1,v2):\n",
    "    dist = haversine((v1['x'],v1['y']),(v2['x'],v2['y']))\n",
    "    return dist\n",
    "\n",
    "\n",
    "def osm_to_ig(node, edge):\n",
    "    \"\"\" Turns a node and edge dataframe into an igraph Graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    G = ig.Graph(directed = False)\n",
    "\n",
    "    x_coords = node['x'].tolist() \n",
    "    y_coords = node['y'].tolist()\n",
    "    ids = node['osmid'].tolist()\n",
    "    coords = []\n",
    "\n",
    "    for i in range(len(x_coords)):\n",
    "        G.add_vertex(x = x_coords[i], y = y_coords[i], id = ids[i])\n",
    "        coords.append((x_coords[i], y_coords[i]))\n",
    "\n",
    "    id_dict = dict(zip(G.vs['id'], np.arange(0, G.vcount()).tolist()))\n",
    "    coords_dict = dict(zip(np.arange(0, G.vcount()).tolist(), coords))\n",
    "\n",
    "    edge_list = []\n",
    "    for i in range(len(edge)):\n",
    "        edge_list.append([id_dict.get(edge['u'][i]), id_dict.get(edge['v'][i])])\n",
    "        \n",
    "    G.add_edges(edge_list)\n",
    "    G.simplify()\n",
    "    new_edges = G.get_edgelist()\n",
    "    \n",
    "    distances_list = []\n",
    "    for i in range(len(new_edges)):\n",
    "        distances_list.append(haversine(coords_dict.get(new_edges[i][0]), coords_dict.get(new_edges[i][1])))\n",
    "\n",
    "    G.es()['weight'] = distances_list\n",
    "    \n",
    "    return G\n",
    "\n",
    "# def ig_to_nx(G_ig):\n",
    "#     \"\"\"Turn an igraph graph into a networkx graph\n",
    "#     \"\"\"\n",
    "#     # https://stackoverflow.com/questions/23235964/interface-between-networkx-and-igraph/45127940#45127940\n",
    "    \n",
    "#     G = nx.Graph()\n",
    "#     ids = G_ig.vs['id']\n",
    "#     G.add_nodes_from(ids)\n",
    "#     G.add_edges_from([(ids[x.source], ids[x.target], {\"weight\":x[\"weight\"]}) for x in G_ig.es])\n",
    "#     return G\n",
    "\n",
    "proj_wgs84 = pyproj.Proj('+proj=longlat +datum=WGS84')\n",
    "def geodesic_point_buffer(lat, lon, km):\n",
    "    # https://gis.stackexchange.com/questions/289044/creating-buffer-circle-x-kilometers-from-point-using-python\n",
    "    \n",
    "    # Azimuthal equidistant projection\n",
    "    aeqd_proj = '+proj=aeqd +lat_0={lat} +lon_0={lon} +x_0=0 +y_0=0'\n",
    "    project = partial(\n",
    "        pyproj.transform,\n",
    "        pyproj.Proj(aeqd_proj.format(lat=lat, lon=lon)),\n",
    "        proj_wgs84)\n",
    "    buf = Point(0, 0).buffer(km * 1000)  # distance in metres\n",
    "    return ops.transform(project, buf).exterior.coords[:]\n",
    "\n",
    "\n",
    "def calculate_directness(G, indices):\n",
    "    \"\"\"Calculate directness on G over all pairs in nodes_sample\n",
    "    \"\"\"\n",
    "    # To do: consider only connected components, or only the largest?\n",
    "    \n",
    "    poi_edges = []\n",
    "    for c, v in enumerate(indices):\n",
    "        poi_edges.append(G.get_shortest_paths(v, indices[c:], weights = \"weight\", output = \"epath\"))\n",
    "    \n",
    "    total_distance_network = 0\n",
    "    for paths_e in poi_edges:\n",
    "        for path_e in paths_e:\n",
    "            # Sum up distances of path segments from first to last node\n",
    "            total_distance_network += sum([G.es[e]['weight'] for e in path_e])\n",
    "    \n",
    "    comb = combinations(indices, 2)\n",
    "    v1 = []\n",
    "    v2 = []\n",
    "    for tup in comb:\n",
    "        v1.append((G.vs[tup[0]][\"x\"], G.vs[tup[0]][\"y\"]))\n",
    "        v2.append((G.vs[tup[1]][\"x\"], G.vs[tup[1]][\"y\"]))\n",
    "    total_distance_haversine = sum(haversine_vector(v1, v2))\n",
    "    \n",
    "    return total_distance_haversine / total_distance_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_carall = pd.read_csv(PATH[\"data\"]+placeid+'_carall_nodes.csv')\n",
    "edge_carall = pd.read_csv(PATH[\"data\"]+placeid+'_carall_edges.csv')\n",
    "G_carall = osm_to_ig(node_carall, edge_carall)\n",
    "\n",
    "if poi_source == \"railwaystation\":\n",
    "    with open(PATH[\"data\"]+placeid+'_poi_railwaystation_nnidscarall.csv') as f:\n",
    "        nnids = [int(line.rstrip()) for line in f]\n",
    "\n",
    "round_coordinates(G_carall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = placeid + '_poi_' + poi_source + \"_\" + prune_measure\n",
    "resultfile = open(PATH[\"results\"] + filename + \".pickle\",'rb')\n",
    "res = pickle.load(resultfile)\n",
    "resultfile.close()\n",
    "# pp.pprint(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost (length)  \n",
    "length / carlength  \n",
    "coverage  \n",
    "directness  \n",
    "compare with existing bike infra  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_place is one static file for the existing city. This can be compared to the generated infrastructure.\n",
    "# Make a check if this file was already generated. If not, generate it:\n",
    "\n",
    "output_place = {\"length_carall\": 0,\n",
    "                \"length_biketrack\": 0,\n",
    "                \"length_bikeable\": 0,\n",
    "                \"length_biketrackcarall\": 0,\n",
    "                \"coverage500m_carall\": 0,\n",
    "                \"coverage500m_biketrack\": 0,\n",
    "                \"coverage500m_bikeable\": 0,\n",
    "                \"coverage500m_biketrackcarall\": 0,\n",
    "                \"directness_carall\": 0,\n",
    "                \"directness_biketrack\": 0,\n",
    "                \"directness_bikeable\": 0,\n",
    "                \"directness_biketrackcarall\": 0,\n",
    "                \"poirailway\": 0,\n",
    "                \"poirailway_coverage500m_carall\": 0,\n",
    "                \"poirailway_coverage500m_biketrack\": 0,\n",
    "                \"poirailway_coverage500m_bikeable\": 0,\n",
    "                \"poirailway_coverage500m_biketrackcarall\": 0,\n",
    "                \"components_carall\": 0,\n",
    "                \"components_biketrack\": 0,\n",
    "                \"components_bikeable\": 0,\n",
    "                \"components_biketrackcarall\": 0\n",
    "               }\n",
    "# To do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output contains lists for all the prune_quantile values of the coresponding results\n",
    "output = {\"length\":[],\n",
    "          \"coverage500m\": [],\n",
    "          \"directness\": [],\n",
    "          \"poirailway_coverage500m\": [],\n",
    "          \"components\": []\n",
    "         }\n",
    "\n",
    "for GT, GT_abstract, prune_quantile in zip(res[\"GTs\"], res[\"GT_abstracts\"], res[\"prune_quantiles\"]):\n",
    "#     print(prune_quantile)\n",
    "    # LENGTH\n",
    "    output[\"length\"].append(sum([e['weight'] for e in GT.es]))\n",
    "    \n",
    "    # COVERAGE\n",
    "    # https://macwright.org/2012/10/31/gis-with-python-shapely-fiona.html\n",
    "    cov = Polygon()\n",
    "    for v in GT.vs:\n",
    "        buf = geodesic_point_buffer(v[\"x\"], v[\"y\"], 0.5) # 500m\n",
    "        cov = ops.unary_union([cov, Polygon(buf)])\n",
    "    \n",
    "    # https://gis.stackexchange.com/questions/127607/area-in-km-from-polygon-of-coordinates\n",
    "    cov_area = ops.transform(\n",
    "        partial(\n",
    "            pyproj.transform,\n",
    "            pyproj.Proj('EPSG:4326'),\n",
    "            pyproj.Proj(\n",
    "                proj='aea',\n",
    "                lat_1=cov.bounds[1],\n",
    "                lat_2=cov.bounds[3])),\n",
    "        cov)\n",
    "    output[\"coverage500m\"].append(cov_area.area / 1000000)\n",
    "    \n",
    "    # POI COVERAGE\n",
    "    pois_indices = set()\n",
    "    for poi in nnids:\n",
    "        pois_indices.add(G_carall.vs.find(id = poi).index)\n",
    "\n",
    "    poiscovered = 0\n",
    "    for poi in pois_indices:\n",
    "        v = G_carall.vs[poi]\n",
    "        if Point(-v[\"y\"], v[\"x\"]).within(cov):\n",
    "            poiscovered += 1\n",
    "    output[\"poirailway_coverage500m\"].append(poiscovered)\n",
    "\n",
    "    # COMPONENTS\n",
    "    output[\"components\"].append(len(list(GT.components())))\n",
    "    \n",
    "    # DIRECTNESS\n",
    "    # Do this on a random subsample for speed reasons\n",
    "    if len(list(GT.components())) == 1:\n",
    "        nodes_sample = random.sample(list(GT.vs), min(500, len(GT.vs)))\n",
    "        output[\"directness\"].append(calculate_directness(GT, [n.index for n in nodes_sample]))\n",
    "    else:\n",
    "        output[\"directness\"].append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(4, 3)) # create figure object with a (width,height)\n",
    "# axes = fig.add_axes([0, 0, 1, 1]) # left, bottom, width, height (range 0 to 1)\n",
    "# x, y = cov.exterior.coords.xy\n",
    "# patch1 = matplotlib.patches.Polygon(np.stack((np.asarray(x), np.asarray(y)), axis=-1))\n",
    "# axes.add_patch(patch1)\n",
    "# axes.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = placeid + '_poi_' + poi_source + \"_\" + prune_measure + \".csv\"\n",
    "\n",
    "with open(PATH[\"results\"] + filename, 'w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(output.keys())\n",
    "    w.writerows(zip(*output.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OSMNX",
   "language": "python",
   "name": "osmnx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
